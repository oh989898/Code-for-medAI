{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Transformer 多模态医学 AI 教程（入门版）\n",
        "\n",
        "本教程面向**完全新手**，一步一步带你完成一个可运行的**多模态医学 AI**小项目：\n",
        "\n",
        "- **图像模态**（模拟医学影像）\n",
        "- **文本模态**（模拟病历/报告）\n",
        "- **Transformer** 作为核心编码器\n",
        "\n",
        "我们将完成：\n",
        "1. 数据准备（含自己的数据如何组织）\n",
        "2. 构建多模态 Transformer 模型\n",
        "3. 训练与评估\n",
        "4. 推理与保存\n",
        "5. 如何扩展到真实数据、预训练与微调\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 0. 环境准备\n",
        "\n",
        "本教程需要 Python 3.9+，以及以下依赖：\n",
        "- `torch`（PyTorch）\n",
        "- `numpy`\n",
        "\n",
        "如果你还没有安装 PyTorch，可以运行：\n",
        "\n",
        "```bash\n",
        "pip install torch --index-url https://download.pytorch.org/whl/cpu\n",
        "```\n",
        "\n",
        "> 说明：此教程使用 CPU 即可运行，速度足够演示。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 0.1 导入依赖\n",
        "import os\n",
        "import random\n",
        "from dataclasses import dataclass\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import Dataset, DataLoader\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 0.2 固定随机种子，保证结果可复现\n",
        "def set_seed(seed: int = 42):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "\n",
        "set_seed(42)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. 数据准备\n",
        "\n",
        "为了让教程**真正可运行**，我们先生成一个**可控的模拟数据集**。\n",
        "你之后可以用真实医学数据替换（后面会详细讲如何组织你的数据）。\n",
        "\n",
        "### 1.1 模拟数据说明\n",
        "- **图像模态**：32×32 的灰度图，模拟医学影像\n",
        "- **文本模态**：简短的中文病历描述\n",
        "- **标签**：二分类（0=正常，1=异常）\n",
        "\n",
        "我们人为制造一点规律，让模型能学到：\n",
        "- 标签=1 时，图像中心有“亮点”\n",
        "- 标签=1 时，文本包含更高概率的“异常词”\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 1.2 构造一个简单的词表\n",
        "vocab = [\n",
        "    '[PAD]', '[UNK]',\n",
        "    '咳嗽', '发热', '胸痛', '气促',\n",
        "    '无明显异常', '影像提示结节', '影像提示炎症', '症状轻微',\n",
        "    '血氧下降', '白细胞升高'\n",
        "]\n",
        "word2id = {w: i for i, w in enumerate(vocab)}\n",
        "id2word = {i: w for w, i in word2id.items()}\n",
        "\n",
        "PAD_ID = word2id['[PAD]']\n",
        "UNK_ID = word2id['[UNK]']\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 1.3 生成模拟数据\n",
        "def generate_synthetic_sample(max_len=6):\n",
        "    # 返回：image (1, 32, 32), text_ids (max_len), label (0/1)\n",
        "    label = np.random.randint(0, 2)\n",
        "\n",
        "    # --- 图像模态 ---\n",
        "    image = np.random.rand(32, 32) * 0.1\n",
        "    if label == 1:\n",
        "        # 在中心区域加亮点，制造可学习模式\n",
        "        image[12:20, 12:20] += 0.8\n",
        "    image = np.clip(image, 0, 1)\n",
        "    image = image.astype(np.float32)[None, :, :]  # (1, 32, 32)\n",
        "\n",
        "    # --- 文本模态 ---\n",
        "    normal_words = ['无明显异常', '症状轻微']\n",
        "    abnormal_words = ['影像提示结节', '影像提示炎症', '血氧下降', '白细胞升高']\n",
        "\n",
        "    words = []\n",
        "    if label == 1:\n",
        "        words += random.sample(abnormal_words, k=2)\n",
        "    else:\n",
        "        words += random.sample(normal_words, k=1)\n",
        "\n",
        "    # 加一些常见症状词\n",
        "    words += random.sample(['咳嗽', '发热', '胸痛', '气促'], k=2)\n",
        "\n",
        "    # 组装并填充\n",
        "    words = words[:max_len]\n",
        "    text_ids = [word2id.get(w, UNK_ID) for w in words]\n",
        "    text_ids += [PAD_ID] * (max_len - len(text_ids))\n",
        "\n",
        "    return image, np.array(text_ids, dtype=np.int64), label\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 1.4 构建 PyTorch Dataset\n",
        "class SyntheticMedDataset(Dataset):\n",
        "    def __init__(self, size=200, max_len=6):\n",
        "        self.samples = [generate_synthetic_sample(max_len=max_len) for _ in range(size)]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.samples)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image, text_ids, label = self.samples[idx]\n",
        "        return (\n",
        "            torch.tensor(image),\n",
        "            torch.tensor(text_ids),\n",
        "            torch.tensor(label, dtype=torch.long),\n",
        "        )\n",
        "\n",
        "# 划分训练/验证集\n",
        "train_dataset = SyntheticMedDataset(size=200, max_len=6)\n",
        "val_dataset = SyntheticMedDataset(size=60, max_len=6)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1.5 如果你用自己的真实数据\n",
        "\n",
        "推荐一个简单清晰的目录结构：\n",
        "\n",
        "```\n",
        "your_dataset/\n",
        "  images/\n",
        "    0001.png\n",
        "    0002.png\n",
        "  reports.csv\n",
        "```\n",
        "\n",
        "`reports.csv` 示例格式：\n",
        "\n",
        "| image_id | text | label |\n",
        "|----------|------|-------|\n",
        "| 0001.png | 患者出现咳嗽、发热 | 1 |\n",
        "| 0002.png | 无明显异常 | 0 |\n",
        "\n",
        "然后你可以：\n",
        "1. 用 `pandas` 读取 `reports.csv`\n",
        "2. 用 `PIL` 或 `opencv` 读取图片\n",
        "3. 把文本分词成 token（可以用简单空格切分，或使用 `jieba`）\n",
        "4. 生成 `Dataset` 对象\n",
        "\n",
        "> 后面会给你“真实数据替换模板”。\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. 构建多模态 Transformer 模型\n",
        "\n",
        "我们将构建两个 Transformer 编码器：\n",
        "- **文本 Transformer**：编码病历文本\n",
        "- **图像 Transformer**：编码医学影像（简化版 ViT）\n",
        "\n",
        "最后把两个模态的 `CLS` 向量拼接，进行分类。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 2.1 文本编码器\n",
        "class TextTransformer(nn.Module):\n",
        "    def __init__(self, vocab_size, d_model=64, nhead=4, num_layers=2, max_len=6):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, d_model)\n",
        "        self.pos_embedding = nn.Parameter(torch.randn(1, max_len, d_model))\n",
        "        encoder_layer = nn.TransformerEncoderLayer(d_model=d_model, nhead=nhead, batch_first=True)\n",
        "        self.encoder = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
        "        self.cls_token = nn.Parameter(torch.randn(1, 1, d_model))\n",
        "\n",
        "    def forward(self, input_ids):\n",
        "        # input_ids: (B, L)\n",
        "        B, L = input_ids.shape\n",
        "        x = self.embedding(input_ids) + self.pos_embedding[:, :L, :]\n",
        "        cls = self.cls_token.expand(B, -1, -1)\n",
        "        x = torch.cat([cls, x], dim=1)  # (B, L+1, d_model)\n",
        "        x = self.encoder(x)\n",
        "        return x[:, 0, :]  # 返回 CLS 向量\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 2.2 图像编码器（简化版 ViT）\n",
        "class ImageTransformer(nn.Module):\n",
        "    def __init__(self, d_model=64, nhead=4, num_layers=2, image_size=32, patch_size=4):\n",
        "        super().__init__()\n",
        "        self.patch_size = patch_size\n",
        "        num_patches = (image_size // patch_size) ** 2\n",
        "\n",
        "        self.patch_embed = nn.Conv2d(1, d_model, kernel_size=patch_size, stride=patch_size)\n",
        "        self.cls_token = nn.Parameter(torch.randn(1, 1, d_model))\n",
        "        self.pos_embedding = nn.Parameter(torch.randn(1, num_patches + 1, d_model))\n",
        "\n",
        "        encoder_layer = nn.TransformerEncoderLayer(d_model=d_model, nhead=nhead, batch_first=True)\n",
        "        self.encoder = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
        "\n",
        "    def forward(self, images):\n",
        "        # images: (B, 1, 32, 32)\n",
        "        x = self.patch_embed(images)  # (B, d_model, 8, 8)\n",
        "        x = x.flatten(2).transpose(1, 2)  # (B, num_patches, d_model)\n",
        "        B = x.size(0)\n",
        "        cls = self.cls_token.expand(B, -1, -1)\n",
        "        x = torch.cat([cls, x], dim=1)\n",
        "        x = x + self.pos_embedding\n",
        "        x = self.encoder(x)\n",
        "        return x[:, 0, :]  # CLS\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 2.3 多模态融合分类器\n",
        "class MultimodalClassifier(nn.Module):\n",
        "    def __init__(self, vocab_size, num_classes=2, d_model=64):\n",
        "        super().__init__()\n",
        "        self.text_encoder = TextTransformer(vocab_size=vocab_size, d_model=d_model)\n",
        "        self.image_encoder = ImageTransformer(d_model=d_model)\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(d_model * 2, d_model),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(d_model, num_classes),\n",
        "        )\n",
        "\n",
        "    def forward(self, images, input_ids):\n",
        "        text_feat = self.text_encoder(input_ids)\n",
        "        image_feat = self.image_encoder(images)\n",
        "        fused = torch.cat([text_feat, image_feat], dim=1)\n",
        "        logits = self.classifier(fused)\n",
        "        return logits\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 2.4 初始化模型\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = MultimodalClassifier(vocab_size=len(vocab)).to(device)\n",
        "model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. 训练模型\n",
        "\n",
        "我们使用交叉熵损失（分类任务），并进行简单训练。\n",
        "为了教程速度，这里训练 5 个 epoch。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 3.1 训练配置\n",
        "epochs = 5\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# 3.2 训练循环\n",
        "for epoch in range(1, epochs + 1):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for images, input_ids, labels in train_loader:\n",
        "        images = images.to(device)\n",
        "        input_ids = input_ids.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        logits = model(images, input_ids)\n",
        "        loss = criterion(logits, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    avg_loss = total_loss / len(train_loader)\n",
        "    print(f'Epoch {epoch} | Train Loss: {avg_loss:.4f}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. 评估模型\n",
        "\n",
        "我们计算验证集准确率。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 4.1 验证集评估\n",
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, input_ids, labels in val_loader:\n",
        "        images = images.to(device)\n",
        "        input_ids = input_ids.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        logits = model(images, input_ids)\n",
        "        preds = logits.argmax(dim=1)\n",
        "        correct += (preds == labels).sum().item()\n",
        "        total += labels.size(0)\n",
        "\n",
        "acc = correct / total\n",
        "print(f'Validation Accuracy: {acc:.2%}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. 推理（预测单个样本）\n",
        "\n",
        "我们从验证集拿一个样本，看看模型的预测。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 5.1 拿一个样本进行推理\n",
        "sample_image, sample_text, sample_label = val_dataset[0]\n",
        "\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    logits = model(sample_image.unsqueeze(0).to(device), sample_text.unsqueeze(0).to(device))\n",
        "    pred = logits.argmax(dim=1).item()\n",
        "\n",
        "print('真实标签:', sample_label.item())\n",
        "print('预测标签:', pred)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. 如何保存与加载模型\n",
        "\n",
        "训练完成后，我们可以保存模型权重，之后继续使用。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 6.1 保存模型\n",
        "save_path = 'multimodal_transformer.pth'\n",
        "torch.save(model.state_dict(), save_path)\n",
        "print('模型已保存到:', save_path)\n",
        "\n",
        "# 6.2 加载模型（示例）\n",
        "loaded_model = MultimodalClassifier(vocab_size=len(vocab)).to(device)\n",
        "loaded_model.load_state_dict(torch.load(save_path, map_location=device))\n",
        "loaded_model.eval()\n",
        "print('模型已加载，可继续推理')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. 用真实数据的替换模板（非常重要）\n",
        "\n",
        "下面给出一个“真实数据替换模板”，你只需要把自己的路径填进去即可。\n",
        "\n",
        "### 7.1 数据结构回顾\n",
        "```\n",
        "your_dataset/\n",
        "  images/\n",
        "    0001.png\n",
        "    0002.png\n",
        "  reports.csv\n",
        "```\n",
        "### 7.2 读取真实数据的代码模板\n",
        "（注意：此段代码是模板，需要你安装 `pandas` 和 `Pillow`）\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# === 真实数据模板示例（可复制替换）===\n",
        "# import pandas as pd\n",
        "# from PIL import Image\n",
        "#\n",
        "# class RealMedDataset(Dataset):\n",
        "#     def __init__(self, csv_path, image_dir, tokenizer, max_len=64):\n",
        "#         self.df = pd.read_csv(csv_path)\n",
        "#         self.image_dir = image_dir\n",
        "#         self.tokenizer = tokenizer  # 你可以自己写一个简单分词器\n",
        "#         self.max_len = max_len\n",
        "#\n",
        "#     def __len__(self):\n",
        "#         return len(self.df)\n",
        "#\n",
        "#     def __getitem__(self, idx):\n",
        "#         row = self.df.iloc[idx]\n",
        "#         image_path = os.path.join(self.image_dir, row['image_id'])\n",
        "#         image = Image.open(image_path).convert('L').resize((32, 32))\n",
        "#         image = np.array(image, dtype=np.float32) / 255.0\n",
        "#         image = torch.tensor(image)[None, :, :]\n",
        "#\n",
        "#         text_ids = self.tokenizer(row['text'], max_len=self.max_len)\n",
        "#         label = torch.tensor(row['label'], dtype=torch.long)\n",
        "#\n",
        "#         return image, text_ids, label\n",
        "#\n",
        "# # 使用方式：\n",
        "# train_dataset = RealMedDataset('your_dataset/reports.csv', 'your_dataset/images', tokenizer)\n",
        "# train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. 预训练与微调（新手也能理解的版本）\n",
        "\n",
        "### 8.1 预训练是什么？\n",
        "- **预训练**：在大量数据上学习通用表示\n",
        "- **微调**：在你的具体任务上继续训练\n",
        "\n",
        "### 8.2 简化版建议\n",
        "如果你是新手，可以这样做：\n",
        "1. 先用本教程的合成数据训练通模型流程\n",
        "2. 再把数据换成你自己的真实数据\n",
        "3. 训练时使用较小学习率（如 1e-4）\n",
        "\n",
        "### 8.3 如何做多模态预训练？\n",
        "这里给你一个简单方向：\n",
        "- **图像端预训练**：使用公开医学影像数据集（如胸片）做分类/自监督\n",
        "- **文本端预训练**：使用大量医学报告做 Masked Language Model\n",
        "- **融合层微调**：把两个编码器接起来，在你的任务上训练\n",
        "\n",
        "> 真实预训练会比较复杂，但流程和本教程是一样的。\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9. 小结\n",
        "\n",
        "你已经完成了一个**可运行的多模态 Transformer 医学 AI 入门项目**：\n",
        "- 数据准备\n",
        "- 模型搭建\n",
        "- 训练与评估\n",
        "- 推理与保存\n",
        "- 真实数据替换与预训练建议\n",
        "\n",
        "如果你想继续拓展，可以尝试：\n",
        "- 增大图像尺寸与模型规模\n",
        "- 使用更真实的医学文本语料\n",
        "- 引入对比学习或多模态预训练\n",
        "\n",
        "祝你学习顺利！\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}