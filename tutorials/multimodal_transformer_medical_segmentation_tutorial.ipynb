{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "# 医学AI多模态Transformer分割入门教程（可运行）\n\n本教程面向**完全不会代码的新手**，一步一步演示如何用**Transformer**做**医学图像分割**，并融合**多模态数据**（图像 + 文本/结构化信息）。\n\n> 为了确保**任何人都能跑通**，我们使用**可控的合成数据**进行演示。\n> 真实项目中只需要把数据读取部分替换成你的医学影像即可。\n\n你将学到：\n1. 如何准备多模态数据（图像 + 文本）\n2. 如何构建一个简化的Transformer分割模型\n3. 如何训练、评估并保存模型\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 0. 环境准备\n\n如果你还没有安装依赖，可以运行下面的命令：\n\n```bash\npip install torch torchvision numpy matplotlib\n```\n\n> 提示：如果你用的是GPU环境，可安装支持CUDA的PyTorch版本。\n"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "# 1. 导入依赖\nimport math\nimport random\nfrom dataclasses import dataclass\n\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader\nimport matplotlib.pyplot as plt\n"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "# 2. 固定随机种子，保证每次结果可复现\nseed = 42\nrandom.seed(seed)\nnp.random.seed(seed)\ntorch.manual_seed(seed)\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 3. 准备“多模态”数据（合成示例）\n\n我们构造一个可运行的小数据集：\n- **图像**：64x64 的灰度图（模拟CT/MRI切片）\n- **文本模态**：简短的病人描述（例如“肿瘤大小大/小”）\n- **标签**：每张图像对应一个分割掩码（白色区域代表病灶）\n\n> 真实项目中，你需要把这里替换为读取DICOM/NIfTI数据、病人报告等。\n"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "# 3.1 生成合成分割数据\n# 我们用简单的几何图形模拟“病灶”区域\n\ndef make_circle_mask(size=64, radius=10, center=None):\n    mask = np.zeros((size, size), dtype=np.float32)\n    if center is None:\n        center = (size // 2, size // 2)\n    yy, xx = np.ogrid[:size, :size]\n    cy, cx = center\n    dist = (yy - cy) ** 2 + (xx - cx) ** 2\n    mask[dist <= radius ** 2] = 1.0\n    return mask\n\n\ndef generate_sample(size=64):\n    # 随机生成“病灶”大小和位置\n    radius = np.random.randint(6, 14)\n    center = (np.random.randint(16, 48), np.random.randint(16, 48))\n\n    mask = make_circle_mask(size=size, radius=radius, center=center)\n\n    # 图像 = 噪声 + 病灶区域增强\n    image = np.random.randn(size, size).astype(np.float32) * 0.2\n    image += mask * np.random.uniform(0.8, 1.2)\n\n    # 文本模态: 简单描述（可扩展为病历文本）\n    if radius >= 10:\n        text = \"tumor is large\"\n    else:\n        text = \"tumor is small\"\n\n    return image, mask, text\n"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "# 3.2 构建PyTorch数据集\n\n# 简单的词表（用于把文本转换成数字）\nvocab = {\n    \"tumor\": 0,\n    \"is\": 1,\n    \"large\": 2,\n    \"small\": 3,\n    \"<pad>\": 4,\n}\n\n\ndef text_to_ids(text, max_len=3):\n    tokens = text.split()\n    ids = [vocab.get(t, vocab[\"<pad>\"]) for t in tokens]\n    # 补齐长度\n    if len(ids) < max_len:\n        ids += [vocab[\"<pad>\"]] * (max_len - len(ids))\n    return ids[:max_len]\n\n\nclass SyntheticMedicalDataset(Dataset):\n    def __init__(self, num_samples=200, size=64):\n        self.samples = [generate_sample(size) for _ in range(num_samples)]\n\n    def __len__(self):\n        return len(self.samples)\n\n    def __getitem__(self, idx):\n        image, mask, text = self.samples[idx]\n        image = torch.tensor(image).unsqueeze(0)  # [1, H, W]\n        mask = torch.tensor(mask).unsqueeze(0)    # [1, H, W]\n        text_ids = torch.tensor(text_to_ids(text))\n        return image, mask, text_ids\n"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "# 3.3 创建DataLoader\ntrain_dataset = SyntheticMedicalDataset(num_samples=200)\nval_dataset = SyntheticMedicalDataset(num_samples=50)\n\ntrain_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\nval_loader = DataLoader(val_dataset, batch_size=8)\n"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "# 3.4 可视化一个样本\nimage, mask, text_ids = train_dataset[0]\n\nplt.figure(figsize=(6, 3))\nplt.subplot(1, 2, 1)\nplt.title(\"Image\")\nplt.imshow(image.squeeze().numpy(), cmap=\"gray\")\n\nplt.subplot(1, 2, 2)\nplt.title(\"Mask\")\nplt.imshow(mask.squeeze().numpy(), cmap=\"gray\")\nplt.show()\n\nprint(\"Text ids:\", text_ids)\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 4. 构建Transformer分割模型（简化版）\n\n我们实现一个**极简的多模态Transformer**：\n- 图像被分成小块（patch）\n- 每个patch转成token后送入Transformer编码器\n- 文本也转成embedding\n- 将图像特征与文本特征融合\n- 最后输出分割mask\n\n> 为了教程简洁，我们只演示核心思想，代码可运行。\n"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "# 4.1 模型定义\n\nclass PatchEmbedding(nn.Module):\n    def __init__(self, img_size=64, patch_size=8, in_chans=1, embed_dim=64):\n        super().__init__()\n        self.img_size = img_size\n        self.patch_size = patch_size\n        self.n_patches = (img_size // patch_size) ** 2\n        self.proj = nn.Conv2d(in_chans, embed_dim, kernel_size=patch_size, stride=patch_size)\n\n    def forward(self, x):\n        # x: [B, C, H, W]\n        x = self.proj(x)  # [B, embed_dim, H/ps, W/ps]\n        x = x.flatten(2).transpose(1, 2)  # [B, N, embed_dim]\n        return x\n\n\nclass MultiModalTransformerSeg(nn.Module):\n    def __init__(self, img_size=64, patch_size=8, vocab_size=5, embed_dim=64, num_layers=2, num_heads=4):\n        super().__init__()\n        self.patch_embed = PatchEmbedding(img_size, patch_size, 1, embed_dim)\n\n        self.text_embed = nn.Embedding(vocab_size, embed_dim)\n\n        encoder_layer = nn.TransformerEncoderLayer(d_model=embed_dim, nhead=num_heads, batch_first=True)\n        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n\n        self.fusion_fc = nn.Linear(embed_dim * 2, embed_dim)\n\n        # 将token还原为feature map\n        self.up_proj = nn.Linear(embed_dim, patch_size * patch_size)\n        self.patch_size = patch_size\n        self.img_size = img_size\n\n    def forward(self, img, text_ids):\n        # 图像patch tokens\n        img_tokens = self.patch_embed(img)  # [B, N, D]\n\n        # 文本token -> 平均作为文本特征\n        text_embeds = self.text_embed(text_ids)  # [B, T, D]\n        text_feat = text_embeds.mean(dim=1, keepdim=True)  # [B, 1, D]\n\n        # 融合：把文本特征扩展到所有patch\n        text_feat_expanded = text_feat.repeat(1, img_tokens.size(1), 1)\n        fused = torch.cat([img_tokens, text_feat_expanded], dim=-1)\n        fused = self.fusion_fc(fused)\n\n        # Transformer编码\n        encoded = self.transformer(fused)  # [B, N, D]\n\n        # 解码成mask\n        patch_logits = self.up_proj(encoded)  # [B, N, patch_size*patch_size]\n\n        # 还原到整图大小\n        B, N, _ = patch_logits.shape\n        patches = patch_logits.view(B, N, self.patch_size, self.patch_size)\n        grid_size = self.img_size // self.patch_size\n        patches = patches.view(B, grid_size, grid_size, self.patch_size, self.patch_size)\n        mask = patches.permute(0, 1, 3, 2, 4).reshape(B, 1, self.img_size, self.img_size)\n        return mask\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 5. 训练与评估\n\n我们使用：\n- **Loss**：二元交叉熵（BCE）\n- **指标**：Dice系数（越高越好）\n"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "# 5.1 定义Loss与评估指标\n\ndef dice_score(pred, target, eps=1e-6):\n    pred = (pred > 0.5).float()\n    intersection = (pred * target).sum()\n    union = pred.sum() + target.sum()\n    return (2 * intersection + eps) / (union + eps)\n\n\nmodel = MultiModalTransformerSeg()\noptimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\ncriterion = nn.BCEWithLogitsLoss()\n"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "# 5.2 训练循环\n\nfor epoch in range(3):\n    model.train()\n    total_loss = 0.0\n\n    for images, masks, text_ids in train_loader:\n        logits = model(images, text_ids)\n        loss = criterion(logits, masks)\n\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n        total_loss += loss.item()\n\n    avg_loss = total_loss / len(train_loader)\n\n    # 验证\n    model.eval()\n    dice_scores = []\n    with torch.no_grad():\n        for images, masks, text_ids in val_loader:\n            logits = model(images, text_ids)\n            probs = torch.sigmoid(logits)\n            dice = dice_score(probs, masks)\n            dice_scores.append(dice.item())\n\n    print(f\"Epoch {epoch+1}: loss={avg_loss:.4f}, dice={np.mean(dice_scores):.4f}\")\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 6. 推理与可视化结果\n\n训练完成后，我们可在一张样本上进行预测并可视化。\n"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "# 6.1 推理示例\nmodel.eval()\nimage, mask, text_ids = val_dataset[0]\n\nwith torch.no_grad():\n    logits = model(image.unsqueeze(0), text_ids.unsqueeze(0))\n    pred = torch.sigmoid(logits).squeeze().numpy()\n\nplt.figure(figsize=(9, 3))\nplt.subplot(1, 3, 1)\nplt.title(\"Image\")\nplt.imshow(image.squeeze().numpy(), cmap=\"gray\")\n\nplt.subplot(1, 3, 2)\nplt.title(\"Ground Truth\")\nplt.imshow(mask.squeeze().numpy(), cmap=\"gray\")\n\nplt.subplot(1, 3, 3)\nplt.title(\"Prediction\")\nplt.imshow(pred, cmap=\"gray\")\nplt.show()\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 7. 保存模型\n\n你可以保存训练好的模型参数，之后加载继续使用。\n"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "# 7.1 保存模型\n\ntorch.save(model.state_dict(), \"multimodal_transformer_seg.pth\")\nprint(\"模型已保存\")\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 8. 下一步建议（真实医学场景）\n\n当你准备处理真实数据时，可以逐步替换：\n1. **数据读取**：使用 `pydicom`/`nibabel` 读取DICOM或NIfTI\n2. **文本模态**：使用真实病历文本或结构化信息\n3. **模型升级**：替换为更强的Transformer（如Swin-UNet、ViT-UNet）\n4. **训练优化**：更多数据、数据增强、学习率调度等\n\n如果需要，我可以帮你把这个教程升级成“真实医学影像数据版本”。\n"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}