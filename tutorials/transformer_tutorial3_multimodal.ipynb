{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "# Transformer Tutorial 3：多模态医学图像分类（超详细新手版）\n\n> 目标：手把手带你完成一个**可运行**的多模态医学图像分类项目。\n>\n> - **模态 1：医学影像**（示例用 MedMNIST 的胸部 X 光）\n> - **模态 2：结构化/文本信息**（示例用“年龄+性别+症状描述”的简化文本）\n>\n> 你将学会：\n> 1. 如何准备数据（自己的数据要怎么放）\n> 2. 如何构建多模态数据集\n> 3. 如何搭建 Transformer 模型（图像 + 文本）\n> 4. 如何训练、评估、保存模型\n> 5. 如何进行预训练与微调的思路\n\n**阅读方式建议**：从上到下顺序执行，每一步我都写了“这是在做什么”的解释。\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 0. 目录与文件结构（新手必读）\n\n本教程默认你在项目根目录运行（例如 `Code-for-medAI/`）。建议你把这个 Notebook 放在：\n\n```\nCode-for-medAI/\n  tutorials/\n    transformer_tutorial3_multimodal.ipynb  ← 本文件\n```\n\n### 你的**自有数据**应该怎么放？\n\n我们推荐如下结构（把图片和文本/表格信息整理到一起）：\n\n```\nmy_dataset/\n  images/\n    train/\n      class0/xxx.png\n      class1/yyy.png\n    val/\n      class0/...\n      class1/...\n  metadata.csv   # 每一行对应一张图（文件名、年龄、性别、症状等）\n```\n\n`metadata.csv` 示例（用逗号分隔）：\n\n```\nimage_id,age,sex,complaint,label\nxxx.png,45,M,咳嗽发热,0\nyyy.png,70,F,胸闷气短,1\n```\n\n> **小白提示**：如果你还没有自己的真实数据，可以先运行本教程的“示例数据”流程。\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 1. 环境准备（安装依赖）\n\n> 如果你是第一次运行，需要安装一些库。\n> 下面的命令可以复制到终端里执行。\n\n我们主要用到：\n- `torch` / `torchvision`：深度学习框架\n- `medmnist`：医学数据集（示例使用）\n- `pandas`：处理表格数据\n\n**注意**：在没有网络的环境下，`pip` 可能无法下载。那就先跳过安装。\n"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "# 如果需要安装依赖，取消下面注释并运行\n# !pip install torch torchvision medmnist pandas scikit-learn tqdm\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 2. 导入库（只是准备，不会立刻训练）\n"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "import os\nfrom dataclasses import dataclass\nfrom typing import List, Dict\n\nimport numpy as np\nimport pandas as pd\nfrom PIL import Image\n\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import transforms\nfrom torchvision.models import vit_b_16\n\nfrom sklearn.metrics import classification_report, confusion_matrix\nfrom tqdm import tqdm\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 3. 准备示例数据（MedMNIST）\n\n我们用 **MedMNIST 的 ChestMNIST** 做演示。它是医学影像分类的标准小数据集。\n\n> 这一步会**自动下载数据**（若网络不可用就会失败）。\n> 如果你有自己的数据，请跳到第 4 节。\n"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "from medmnist import ChestMNIST\n\n# 这里下载并加载示例数据集\ntrain_dataset_raw = ChestMNIST(split=\"train\", download=True)\nval_dataset_raw = ChestMNIST(split=\"val\", download=True)\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "### 3.1 为示例数据创建“伪文本信息”\n\nChestMNIST 本身只有图片和标签，没有文本信息。\n为了演示“多模态”，我们**人为构造**一些简单文本：\n- 随机年龄\n- 随机性别\n- “症状描述”（用标签映射）\n\n这样你就能看到**图像 + 文本**一起训练。\n"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "import random\n\nsymptom_map = {\n    0: \"无明显异常\",\n    1: \"肺部异常\",\n}\n\n\ndef build_fake_text(label: int) -> str:\n    age = random.randint(18, 90)\n    sex = random.choice([\"男\", \"女\"])\n    symptom = symptom_map.get(label, \"未知\")\n    return f\"年龄{age}岁，性别{sex}，症状：{symptom}\"\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 4. 文本处理：把中文文本变成模型能理解的数字\n\n对于新手来说，最简单的方法是：\n1. 把文本切成“字”或“词”\n2. 映射成数字 ID\n3. 用 embedding 表示\n\n我们这里用**按字切分**，并用一个最小的“词表”。\n"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "# 1) 先准备一个最简单的字典（包含常见字符）\n# 你也可以替换成真正的分词器（如 transformers 的 tokenizer）\n\nSPECIAL_TOKENS = [\"<PAD>\", \"<UNK>\"]\n\n\ndef build_vocab(texts: List[str], min_freq: int = 1) -> Dict[str, int]:\n    counter = {}\n    for t in texts:\n        for ch in t:\n            counter[ch] = counter.get(ch, 0) + 1\n    vocab = {tok: idx for idx, tok in enumerate(SPECIAL_TOKENS)}\n    for ch, cnt in counter.items():\n        if cnt >= min_freq and ch not in vocab:\n            vocab[ch] = len(vocab)\n    return vocab\n\n\ndef encode_text(text: str, vocab: Dict[str, int], max_len: int = 50) -> List[int]:\n    ids = [vocab.get(ch, vocab[\"<UNK>\"]) for ch in text]\n    ids = ids[:max_len]\n    if len(ids) < max_len:\n        ids += [vocab[\"<PAD>\"]] * (max_len - len(ids))\n    return ids\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 5. 构建多模态数据集（图像 + 文本）\n\n我们将“图像”和“文本”合成一个 Dataset：\n- `image`：Tensor\n- `text_ids`：Tensor\n- `label`：Tensor\n"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "@dataclass\nclass MultiModalConfig:\n    image_size: int = 224\n    max_text_len: int = 50\n\n\nclass MultiModalDataset(Dataset):\n    def __init__(self, raw_dataset, vocab, config: MultiModalConfig, transform=None):\n        self.raw_dataset = raw_dataset\n        self.vocab = vocab\n        self.config = config\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.raw_dataset)\n\n    def __getitem__(self, idx):\n        image, label = self.raw_dataset[idx]\n        label = int(label)\n\n        # 生成伪文本\n        text = build_fake_text(label)\n        text_ids = encode_text(text, self.vocab, self.config.max_text_len)\n\n        # 图像转换\n        if self.transform:\n            image = self.transform(image)\n\n        return {\n            \"image\": image,\n            \"text_ids\": torch.tensor(text_ids, dtype=torch.long),\n            \"label\": torch.tensor(label, dtype=torch.long),\n        }\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "### 5.1 生成词表和 DataLoader\n"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "config = MultiModalConfig()\n\n# 先构造所有文本，生成词表\nall_texts = [build_fake_text(int(train_dataset_raw[i][1])) for i in range(len(train_dataset_raw))]\nvocab = build_vocab(all_texts)\n\nimage_transform = transforms.Compose([\n    transforms.Resize((config.image_size, config.image_size)),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.5], std=[0.5]),\n])\n\ntrain_dataset = MultiModalDataset(train_dataset_raw, vocab, config, transform=image_transform)\nval_dataset = MultiModalDataset(val_dataset_raw, vocab, config, transform=image_transform)\n\ntrain_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\nval_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n\nprint(\"训练样本数：\", len(train_dataset))\nprint(\"验证样本数：\", len(val_dataset))\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 6. 构建多模态 Transformer 模型\n\n模型结构分成三部分：\n\n1. **图像编码器**（Vision Transformer, ViT）\n2. **文本编码器**（简单 Transformer Encoder）\n3. **融合 + 分类头**（concat 后 MLP 分类）\n\n> 注意：如果你电脑配置低，可以把 ViT 换成 ResNet，或者把 `weights=None`（不下载预训练权重）。\n"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "class TextEncoder(nn.Module):\n    def __init__(self, vocab_size: int, embed_dim: int = 128, num_heads: int = 4, num_layers: int = 2):\n        super().__init__()\n        self.embedding = nn.Embedding(vocab_size, embed_dim)\n        encoder_layer = nn.TransformerEncoderLayer(d_model=embed_dim, nhead=num_heads, batch_first=True)\n        self.encoder = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n\n    def forward(self, text_ids):\n        # text_ids: [B, T]\n        x = self.embedding(text_ids)  # [B, T, D]\n        x = self.encoder(x)\n        # 取平均池化作为文本特征\n        return x.mean(dim=1)\n\n\nclass MultiModalTransformer(nn.Module):\n    def __init__(self, num_classes: int, vocab_size: int):\n        super().__init__()\n        # 图像编码器（ViT）\n        self.image_encoder = vit_b_16(weights=None)\n        image_feature_dim = self.image_encoder.heads.head.in_features\n        self.image_encoder.heads = nn.Identity()\n\n        # 文本编码器\n        self.text_encoder = TextEncoder(vocab_size=vocab_size)\n        text_feature_dim = 128\n\n        # 融合与分类\n        self.classifier = nn.Sequential(\n            nn.Linear(image_feature_dim + text_feature_dim, 256),\n            nn.ReLU(),\n            nn.Dropout(0.2),\n            nn.Linear(256, num_classes),\n        )\n\n    def forward(self, image, text_ids):\n        img_feat = self.image_encoder(image)\n        txt_feat = self.text_encoder(text_ids)\n        fused = torch.cat([img_feat, txt_feat], dim=1)\n        return self.classifier(fused)\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 7. 训练准备\n\n我们准备：\n- loss 函数\n- 优化器\n- 训练循环\n"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\nnum_classes = len(train_dataset_raw.labels[0]) if hasattr(train_dataset_raw, \"labels\") else 2\nmodel = MultiModalTransformer(num_classes=num_classes, vocab_size=len(vocab)).to(device)\n\ncriterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 8. 训练模型（一步一步说明）\n\n我们写一个最清晰的训练函数：\n- 逐 batch 前向传播\n- 计算 loss\n- 反向传播更新\n"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "def train_one_epoch(model, loader, optimizer, criterion, device):\n    model.train()\n    total_loss = 0.0\n\n    for batch in tqdm(loader, desc=\"Training\"):\n        images = batch[\"image\"].to(device)\n        text_ids = batch[\"text_ids\"].to(device)\n        labels = batch[\"label\"].to(device)\n\n        optimizer.zero_grad()\n        outputs = model(images, text_ids)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n\n        total_loss += loss.item()\n\n    return total_loss / len(loader)\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 9. 验证 / 评估\n\n评估时要：\n- 关闭梯度\n- 计算准确率和分类报告\n"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "def evaluate(model, loader, device):\n    model.eval()\n    all_preds = []\n    all_labels = []\n\n    with torch.no_grad():\n        for batch in tqdm(loader, desc=\"Evaluating\"):\n            images = batch[\"image\"].to(device)\n            text_ids = batch[\"text_ids\"].to(device)\n            labels = batch[\"label\"].to(device)\n\n            outputs = model(images, text_ids)\n            preds = torch.argmax(outputs, dim=1)\n\n            all_preds.extend(preds.cpu().numpy())\n            all_labels.extend(labels.cpu().numpy())\n\n    print(classification_report(all_labels, all_preds))\n    print(\"Confusion Matrix:\n\", confusion_matrix(all_labels, all_preds))\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 10. 开始训练（完整流程）\n\n> 初学者建议先训练 1-2 个 epoch 观察是否跑通。\n"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "EPOCHS = 2\nfor epoch in range(EPOCHS):\n    loss = train_one_epoch(model, train_loader, optimizer, criterion, device)\n    print(f\"Epoch {epoch+1}/{EPOCHS} - Loss: {loss:.4f}\")\n    evaluate(model, val_loader, device)\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 11. 保存与加载模型\n\n训练完成后保存模型，方便以后继续训练或部署。\n"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "# 保存\ntorch.save(model.state_dict(), \"multimodal_vit.pth\")\n\n# 加载（再次使用时）\n# model = MultiModalTransformer(num_classes=num_classes, vocab_size=len(vocab))\n# model.load_state_dict(torch.load(\"multimodal_vit.pth\", map_location=device))\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 12. 如何进行预训练 & 微调（关键概念）\n\n### 12.1 预训练（Pre-training）\n- 意思是：先在**大数据**上训练一个“通用模型”\n- 对图像：可以使用 ImageNet 预训练 ViT\n- 对文本：可以使用 BERT / RoBERTa 等\n\n### 12.2 微调（Fine-tuning）\n- 意思是：把预训练模型用在你的**小数据**上\n- 一般流程：\n  1. 加载预训练权重\n  2. 替换最后一层分类头\n  3. 用小学习率训练\n\n### 12.3 在本教程中如何做\n\n你可以这样做：\n\n```python\n# 使用预训练 ViT 权重（需要联网下载）\nself.image_encoder = vit_b_16(weights=\"IMAGENET1K_V1\")\n\n# 其他步骤不变\n```\n\n如果你的文本非常多，可以用 `transformers` 的 BERT：\n\n```python\nfrom transformers import BertModel\nself.text_encoder = BertModel.from_pretrained(\"bert-base-chinese\")\n```\n\n> 由于教程要“可运行”，我们用最简版本演示。\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 13. 你自己的数据怎么对接？\n\n核心步骤：\n\n1. **整理图像**：放在 `images/train/` 和 `images/val/` 里。\n2. **整理文本/表格**：制作 `metadata.csv`（包含 image_id, age, sex, complaint, label）\n3. **写一个自定义 Dataset**：\n   - 读取图片\n   - 读取 CSV 中对应行\n   - 生成文本/数值特征\n\n> 你可以参考下面的伪代码：\n"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "class MyCustomDataset(Dataset):\n    def __init__(self, csv_path, image_dir, vocab, config, transform=None):\n        self.df = pd.read_csv(csv_path)\n        self.image_dir = image_dir\n        self.vocab = vocab\n        self.config = config\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.df)\n\n    def __getitem__(self, idx):\n        row = self.df.iloc[idx]\n        image_path = os.path.join(self.image_dir, row[\"image_id\"])\n        image = Image.open(image_path).convert(\"RGB\")\n\n        text = f\"年龄{row['age']}岁，性别{row['sex']}，症状：{row['complaint']}\"\n        text_ids = encode_text(text, self.vocab, self.config.max_text_len)\n\n        if self.transform:\n            image = self.transform(image)\n\n        label = int(row[\"label\"])\n        return {\n            \"image\": image,\n            \"text_ids\": torch.tensor(text_ids),\n            \"label\": torch.tensor(label),\n        }\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 14. 总结\n\n你已经完成了：\n✅ 数据准备（示例 + 自己数据结构）\n✅ 多模态 Dataset\n✅ Transformer 模型（图像 + 文本）\n✅ 训练 + 评估\n✅ 预训练/微调思路\n\n如果你愿意，我还可以继续帮你扩展：\n- 引入真实 BERT\n- 引入更复杂的医学文本结构\n- 加入 3D 影像（CT/MRI）\n- 加入多任务学习（分割 + 分类）\n"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}